
--SEMANTIC CONSTANTS--
insize = 5
outsize = 5
layerstructure = <50>
layerNo = #layerstructure 
maxSize = 50

   
--CHANNELS AND DATA TYPES: 

--Context channel: 

core_real = { -1..1}

--Decisions: 

datatype decisions = coc | wl | wr | sl | sr 

channel context_input:{1..insize}.core_real

--We expect a single output of all possible decisions, for every trace. 
channel context_output:Set({coc, wl, wr, sl, sr})

--NO UNCERTAINTY, we don't need to transmit uncertainty. Activation strength chaining. 
--could have, a dot, pattern matching? 
--Add active, we CAN use it. 
--ZERO IS NEVER TRANSMITTED, IT IS CALCULATED. 
datatype InternalPhases = Zero | Inactive | Active
datatype Phases = inactive | active | uncertain

channel NodePhase:{0..layerNo}.{1..maxSize}.Phases

channel end 

--4 inactive nodes, try to make them all active, 
--won't have a condition. 

--ASSUME WORST CASE UNCERTAINTY, that, for us, is 
EdgeLogic(input_phase, weight, first) = 
	if(first == true) then 
		if(input_phase == inactive)
			then 
				if(weight == inactive)
					then 
						Active
					else
						Inactive
			else
				if(weight == inactive)
					then
						Active
					else
						Inactive
	else 
		if(input_phase == inactive)
			then 
				Zero
			else if (input_phase == active)
				then 
				(if(weight == inactive)
					then
						Inactive
					else
						Active)
			else
				if(input_phase == active)
					then 
						Active
					else
						Inactive

--Proving active for an ACTIVE node. 			
Activation(l,n,edge_results) = 
	if(member(Inactive, set(edge_results))) 
		then
			False
		else
			True

InActivation(l,n,edge_results) = 
	if(member(Active, set(edge_results)))
		then
			False
		else
			True



--If activation logic is FALSE, then it is active.
--Activation Logic means we are UNSURE, TRUE IS UNSURE, FALSE IS ACTIVE.  
Node(layer, node, index) = let
	C(layer, node, 0, edge_results) = 
		((extract_biases(layer,node) == active) & ( 
				((InActivation(layer, node, edge_results) == True) &(
					NodePhase.layer.node!uncertain -> SKIP ))
				[] 
				((InActivation(layer, node, edge_results) == False) &
					NodePhase.layer.node!active -> SKIP)
			)
		) 
		[]
		((extract_biases(layer,node) == inactive) & (
			((Activation(layer, node, edge_results) == True) & (
				NodePhase.layer.node!uncertain -> SKIP )) 
			[]
			((Activation(layer, node, edge_results) == False) & 
				NodePhase.layer.node!inactive -> SKIP)
			)
		)
			
	C(layer, node, index, edge_results) = NodePhase.(layer-1).index?edge_phase ->
		 C(layer, node, (index-1), <EdgeLogic(edge_phase, extract_weights(layer, node, index), (layer==1))>^edge_results)
	
	within 
		C(layer, node, index, <>)
	
HiddenLayer(layer, size, inputSize) = 
	[| {| NodePhase.(layer-1) |} |] i: {1..size} @ Node(layer, i, inputSize) 

HiddenLayers = 
	|| i : {1..layerNo} @
		[ {| NodePhase.(i-1), NodePhase.i |} ] 
		HiddenLayer(i, layerSize(i), layerSize(i-1))  
		
--We can remove this, no, for analysis without another component, add this as context. 

--Doesn't make 0 avaliable, external choice, as it should be, waits on the context to decide one of the other, then 
--It passes them to the first layer. Triggers the first layer. 
--fixed to just inactive for now. 
InputLayer = 
	(; i : <0..insize-1> @ ( NodePhase.0.(insize-i).active -> SKIP ))
	
--Directly from the paper, this is the acas xu. 
context_translation(1) = coc
context_translation(2) = wl
context_translation(3) = wr 
context_translation(4) = sl
context_translation(5) = sr 

--This is the new output layer: 
--BIAS IS NOT ABSOLUTE VALUE, BIAS IS LITERAL VALUE 
bias_order = <2, 5, 4, 3, 1>

--Function: 
--Weight IS ABSOLUTE VALUE. 
weight_order(1) = <4, 3, 5, 2, 1>
weight_order(2) = <1, 2, 3, 4, 5>
weight_order(3) = <1, 3, 2, 5, 4>
weight_order(4) = <4, 2, 3, 1, 5>
weight_order(5) = <1, 2, 4, 3, 5>
weight_order(_) = <1,2,4,3,5>

--Function, 
--If yes, COULD be max> 
--Only for, 
--if any is max, 
isMax(n, s) = 
	if (head(s) == n) 
		then 
			True 
		else 
			False
		
--Active or uncertain, POST WEIGHTING, assume active? Yes. Order cant change, 
couldNodeMax(n, results) = 
	if (not (member(True, { isMax(n, weight_order(i)) | i <- {1..layerSize(layerNo)}, extract_sequence(i, results) == active or extract_sequence(i, results) == uncertain}))  and 
		isMax(n, bias_order) == False) 
		then 
			False
		else 
			True 
	

--All we need to do, is add this to the guard. 
OutputLayer = let	
	C(0, network_results) = 
		context_output!{ context_translation(i) | i <- {1..#network_results}, couldNodeMax(i, network_results) == True} -> SKIP
	
	C(index, network_results) = NodePhase.layerNo.index?output -> C((index-1), <output>^network_results)
										
	within 
		C(layerSize(layerNo), <>)

T = (InputLayer [| {| NodePhase.0 |} |] HiddenLayers)  

--Better if the output interpreter inside the main function, needs to be because of the recursion.
ANN = ( (InputLayer [| {| NodePhase.0 |} |] HiddenLayers)  
		[| {| NodePhase.layerNo |} |] 
	   OutputLayer)

--assert ANN :[deadlock-free]

assert T:[deadlock-free]


--HELPER FUNCTIONS: 
-- Extraction Functions, because random access not implemented in CSPM, implemented as lists not a type of function --

extract_sequence(1, sequence) = head(sequence)
extract_sequence(index, sequence) = extract_sequence((index-1), tail(sequence))

layerSize(0) = insize
layerSize(layer) = extract_sequence(layer, layerstructure)

--Extract single weights value
--extract_weights(layer, node, index) = extract_sequence(index, 
					--(extract_sequence(node, 
						--(extract_sequence(layer, weights)))))
--Extract weights of node
--extract_biases(layer, node) = (extract_sequence(node, 
--											(extract_sequence(layer, biases))))
		
extract_weights(layer, node, index) = active 
extract_biases(layer, node) = active
										
