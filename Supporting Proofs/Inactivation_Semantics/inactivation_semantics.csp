--Normal semantics: 
		
--SEMANTIC CONSTANTS--
insize = 5
outsize = 5
layerstructure = <5, 5> 
layerNo = #layerstructure 
maxSize = 5


--CHANNELS AND DATA TYPES: 

--Context channel: 

core_real = { -2..2}


datatype Phases = active | inactive | uncertain

channel NodePhase:{0..layerNo}.{1..maxSize}.Phases

--This is the intermediate channel, weight concatenation channel, 
channel EdgePhase:{1..layerNo}.{1..maxSize}.{1..maxSize}.Phases

channel end 

weights = 
	<
		< 
			<active,inactive,inactive,active,active>,
			<inactive,active,inactive,active,inactive>,
			<active,active,active,inactive,active>,
			<inactive,inactive,inactive,active,inactive>,
			<inactive,active,active,active,inactive>
		>,

		<
			<inactive,active,inactive,active,active>,
			<active,active,inactive,active,inactive>,
			<inactive,inactive,active,active,inactive>,
			<inactive,active,active,inactive,active>,
			<inactive,active,inactive,active,inactive>
		> 
	>

	


biases = 
	< 
		<active,inactive,active,inactive,inactive>,
		<inactive,active,inactive,inactive,inactive>
	>

--This HOLDS FOR ACTIVATION FUNCTIONS that have a minimum at 0, the uncertainty reduction. 
EdgeLogic(input_phase, weight) = 
	if (input_phase == active) 
		then 
			if(weight == active) 
				then 
					active 
				else 
					inactive
		else 
			if(input_phase == inactive) 
				then 
					inactive 
				else 
					if(input_phase == uncertain) 
						then 
							if(weight == inactive) 
								then 
									inactive 
								else 
									inactive
						else 
							inactive
							
									
					
					

--If its over any weight?

--DONE, 
NodeEdge(layer, node, index) = 
	NodePhase.(layer - 1).index?phase ->
	
	EdgePhase.layer.node.index!(EdgeLogic(phase, extract_weights(layer, node, index))) -> 
	
	SKIP

--This needs to be different for every single node. We need to define quite a large function for this. 
--For every l and n, this is the core of the idea. 
--Needs to be a sequence, not a set. Also, we need a different behaviour for first hidden layer, because
--The input will be quantized, it won't be active or inactive. 
ActivationLogic(edge_results, bias) = 
	(not ( member(inactive, edge_results) ) and (bias == active)) 
	
InactivationLogic(edge_results, bias) = 
	(not ( member(active, edge_results) ) and (bias == inactive))
	

EdgeCollator(layer, node, index) = let
	C(layer, node, 0, edge_results) = 
		(ActivationLogic(edge_results, extract_biases(layer, node)) & 
			NodePhase.layer.node!active -> SKIP)
		[] 
		(InactivationLogic(edge_results, extract_biases(layer, node)) &
			NodePhase.layer.node!inactive -> SKIP) 
			
		[] 
		(not(ActivationLogic(edge_results, extract_biases(layer, node))) and not(InactivationLogic(edge_results, extract_biases(layer, node))) & 
			( 
			(NodePhase.layer.node!uncertain -> SKIP) 
			)
		)
	
	C(layer, node, index, edge_results) = EdgePhase.layer.node.index?edge_phase -> 
										C(layer, node, (index-1), union(edge_results, {edge_phase}))
	within 
		C(layer, node, index, {})


Node(layer, node, inputSize) = 
	(||| i:{1..inputSize} @ NodeEdge(layer, node, i)) 
		[| {| EdgePhase.layer.node |} |]
	EdgeCollator(layer, node, inputSize) \ {| EdgePhase |} 
	

HiddenLayer(layer, size, inputSize) = 
	[| {| NodePhase.(layer-1) |} |] i: {1..size} @ Node(layer, i, inputSize) 

HiddenLayers = 
	|| i : {1..(layerNo-1)} @
		[ {| NodePhase.(i-1), NodePhase.i |} ] 
		HiddenLayer(i, layerSize(i), layerSize(i-1))  

OutputLayer = [| {| NodePhase.(layerNo-1) |} |] 
			i: {1..outsize} @ Node(layerNo, i, layerSize(layerNo-1))


ANNHiddenEvts = diff(Events, {| NodePhase.0, NodePhase.layerNo, end |})

InputLayer = 
	(||| i : {1..insize} @ ( (NodePhase.0.i.active -> SKIP) [] (NodePhase.0.i.inactive -> SKIP) ) )

ANN = (( ( InputLayer [| {| NodePhase.0 |} |] HiddenLayers ) [| {| NodePhase.(layerNo-1) |} |] OutputLayer) \ ANNHiddenEvts) ; ANN 

assert ANN \ {NodePhase.2.1.active } [T= ANN


--We need a VISIBLE EVENTS VERSION. 
ANN_Visible = (( ( InputLayer [| {| NodePhase.0 |} |] HiddenLayers ) [| {| NodePhase.(layerNo-1) |} |] OutputLayer)) ; ANN 


channel a, b, c

assert (a -> SKIP |~| b -> SKIP) [T= (a -> SKIP) 

assert (a -> SKIP) [T= (a -> SKIP |~| b -> SKIP)

assert ((a -> SKIP |~| b -> SKIP) \ { b }) [T= (b -> SKIP)

--HIDING ACTIVE, SO CHECKING FOR DEAD BEHAVIOR. 
assert ANN_Visible \ { NodePhase.1.1.active } [T= ANN_Visible 


assert (HiddenLayer(1,5,5) [| {| NodePhase.1 |} |] Node(2,1,5)) \ {NodePhase.2.1.active } [T=
		(HiddenLayer(1,5,5) [| {| NodePhase.1 |} |] Node(2,1,5))

assert (HiddenLayer(1,5,5) [| {| NodePhase.1 |} |] Node(2,1,5)) \ {NodePhase.2.1.inactive } [T=
		(HiddenLayer(1,5,5) [| {| NodePhase.1 |} |] Node(2,1,5))

assert (HiddenLayer(1,5,5) [| {| NodePhase.1 |} |] Node(2,1,5)) \ {NodePhase.2.1.uncertain } [T=
		(HiddenLayer(1,5,5) [| {| NodePhase.1 |} |] Node(2,1,5))



assert EdgeCollator(2, 1, 1):[deterministic[FD]]



--HELPER FUNCTIONS: 
-- Extraction Functions, because random access not implemented in CSPM, implemented as lists not a type of function --

extract_sequence(1, sequence) = head(sequence)
extract_sequence(index, sequence) = extract_sequence((index-1), tail(sequence))

layerSize(0) = insize
layerSize(layer) = extract_sequence(layer, layerstructure)

--Extract single weights value
extract_weights(layer, node, index) = extract_sequence(index, 
					(extract_sequence(node, 
						(extract_sequence(layer, weights)))))
--Extract weights of node
extract_weights_node(layer, node) = extract_sequence(node, 
							(extract_sequence(layer, weights)))
extract_biases(layer, node) = (extract_sequence(node, 
											(extract_sequence(layer, biases))))
											
										
