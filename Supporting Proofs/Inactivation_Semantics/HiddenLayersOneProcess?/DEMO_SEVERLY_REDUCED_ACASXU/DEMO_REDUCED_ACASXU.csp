--ASSUMPTIONS:
--
--INPUT LAYER IS ALWAYS ACTIVE AND HAS AN EQUAL VALUES, IN1=IN2=... 

--We are testing HIDDEN LAYERS AS A SINGLE PROCESS, LITERALLY IS HIDDEN LAYERS || OUTPUT LAYER. 

--Just the guard is going to be massive, guard for what 

--But it recieves all inputs in order, ALL HIDDEN LAYERS ARE LIKE ONE SINGLE COLLATOR. 

--IN TERMS OF INPUT. 


--SEMANTIC CONSTANTS--
--WE STILL NEED ALL OF THESE, 
insize = 5
outsize = 5
--Can scale on PC to <5>
--server to: <5>
layerstructure = <50>
layerNo = #layerstructure 


--Weights and Biases: 

weights = 
	<
		< 
			<active,inactive,inactive,active,active>,
			<inactive,active,inactive,active,inactive>,
			<active,active,active,inactive,active>,
			<inactive,inactive,inactive,active,inactive>,
			<inactive,active,active,active,inactive>
		>,

		<
			<inactive,active,inactive,active,active>,
			<active,active,inactive,active,inactive>,
			<inactive,inactive,active,active,inactive>,
			<inactive,active,active,inactive,active>,
			<inactive,active,inactive,active,active>
		>
	>

	


biases = 
	< 
		<active,inactive,active,inactive,inactive>,
		<inactive,active,inactive,inactive,inactive>
	>
   
--CHANNELS AND DATA TYPES: 

--Context channel: 

core_real = { -1..1}

--Decisions: 

datatype decisions = coc | wl | wr | sl | sr 

datatype MinMax = Min | Max

channel context_input:{1..insize}.core_real

--We expect a single output of all possible decisions, for every trace. 
channel context_output:Set({coc, wl, wr, sl, sr})


--THESE ARE NOT TRANSMITTED, JUST USED INTERNALLY.
--HERE INACTIVE MEANS -, ZERO DOES MEAN ZERO. 
--UNCERTAIN WE TREAT AS ACTIVE in most situations.
--We can have loads here, because we have so few channels.
--BUT WE DON'T NEED THEM ANYMORE, we can do nondeterminism with this. 
datatype NodePhases = inactive | active

--This is for the OUTPUT OF THE LAST HIDDEN LAYER, 
--We now have so few channels, nodephase, this is for inputlayer, then just last hidden layer. 
--
channel InputLayerPhase:{1..insize}.NodePhases
channel HiddenNodePhase:{1..layerSize(layerNo)}.NodePhases
--STILL NO NONDETERMINISM, BECAUSE WE HAVE UNCERTAIN, transmitting same thing, although we could easily have nondeterminism, it would still work. 

channel end 

--This is for RELU: 
--IF WE ARE UNCERTAIN, WE ASSUME 
			

isFirstLayerInactive(layer,node,edge,bias) = False
--THIS RETURNS TRUE IF, FOR EVERY POSITIVE VALUE, THERE IS A NEGATIVE 
--VALUE > 0, SUCH THAT, IF ITS TRUE, THEN POSSET < NEGSET, MUST BE. 
--MUST BE THE CASE THAT THE SUM, GIVEN THE INPUTS ARE POSITIVE AND THE SAME, 
--THEN POSSET < NEGSET, SO, THE SUMMATION IS *NEGATIVE*, TRUE IS NEGATIVE.
--FALSE IS COULD BE POSITIVE. 
--We can prove in some instances that it MUST BE NEGATIVE.

--To prove its POSITIVE, just INVERT IT, THEN WE CAN SOMETIMES PROVE ITS POSITIVE. 
--By just, the same but BACKWAREDS. 
isWeightSumNegative(layer, node, posSet, negSet) = 
	testPosRelation(layer, node, seq(posSet), negSet)

isWeightSumPositive(layer, node, posSet, negSet) = 
	testPosRelation(layer, node, seq(negSet), posSet)



weightOrderTest = <1,2,4,3,5>

WeightOrder(w1, w2) = IterateList(weightOrderTest, w1, w2)

IterateList(<>, w1, w2) = False
IterateList(l, w1, w2) = 
	if (head(l) == w1) 
		then
			True
		
	else if (head(l) == w2) 
		then 
			False 
	else 
		IterateList(tail(l), w1, w2)
	

extractPosWeights(layer, node) = {i | i <- {1..layerSize(layer-1)}, extract_weights(layer, node, i) == inactive}
extractNegWeights(layer, node) = {i | i <- {1..layerSize(layer-1)}, extract_weights(layer, node, i) == active}

testPosRelation(_, _, <>, _) = True
testPosRelation(layer, node, posIndicies, negSet) = 
	if(card({ neg_i | neg_i <- negSet, WeightOrder(head(posIndicies), neg_i)  }) > 0) 
		then 
			testPosRelation(layer, node, tail(posIndicies), 
				diff(negSet, {getLowestIndex(layer, node, { neg_i | neg_i <- negSet, WeightOrder(head(posIndicies), neg_i)  })}))
		else 
			False
			
getLowestIndex(layer, node, negISet) = 
	head(weightOrderSort(seq(negISet)))

weightOrderSort(seqI) = 
	if(#seqI <= 1) then
		seqI
	else
		
		merge(
			weightOrderSort(<extract_sequence(i, seqI) | i <- <1..(#seqI)/2>>),
			weightOrderSort(<extract_sequence(i, seqI) | i <- <(#seqI)/2+1..#seqI>>)
			)

merge(left, right) = mergeF(left, right, <>)

mergeF(<>, <>, result) = result
mergeF(left, <>, result) = mergeF(tail(left), <>, result^<head(left)>)
mergeF(<>, right, result) = mergeF(<>, tail(right), result^<head(right)>)
mergeF(left, right, result) = 
	if(WeightOrder(head(left), head(right)) == True)
		then 
			mergeF(tail(left), right, result^<head(left)>)
	else
		mergeF(left, tail(right), result^<head(right)>)
			

--Need to recieve all inputs, going to have a massive gigantic huge guard, need to find a way of making this, local definition again? 
--Find a way of writing this better, another process I think, but a simple one.
--reluedgelogic, NO EDGE LOGIC, WE WILL COMPUTE OURSELVES. 
isInactive(input) = False 
isActive(input) = False
HiddenLayers = let
	L(0, input) = 
		(isActive(input) == True) &(
				(; i : <0..layerSize(layerNo)-1> @ HiddenNodePhase.(layerSize(layerNo)-i)!active -> SKIP ))
		[] 
		(isInactive(input) == True) &(
				(; i : <0..layerSize(layerNo)-1> @ HiddenNodePhase.(layerSize(layerNo)-i)!inactive -> SKIP ))
		[] 
		(isInactive(input) == False and isActive(input) == False) &(
				(; i : <0..layerSize(layerNo)-1> @ (HiddenNodePhase.(layerSize(layerNo)-i)!inactive -> SKIP) |~|  (HiddenNodePhase.(layerSize(layerNo)-i)!active -> SKIP)  ))
			
	L(index, input) = InputLayerPhase.index?in -> L((index-1), <in>^input)
	within 
		L(insize, <>)


--We can remove this, no, for analysis without another component, add this as context. 

--Doesn't make 0 avaliable, external choice, as it should be, waits on the context to decide one of the other, then 
--It passes them to the first layer. Triggers the first layer. 
--fixed to just inactive for now. 
--TRANSMITS UNCERTAIN, IT MEANS ACTIVE, it is treated as active. 
InputLayer = 
	(; i : <0..insize-1> @ ( InputLayerPhase.(insize - i).active -> SKIP ))

--Directly from the paper, this is the acas xu. 
context_translation(1) = coc
context_translation(2) = wl
context_translation(3) = wr 
context_translation(4) = sl
context_translation(5) = sr 

emptylogic(false, _) = false 
emptylogic(true, x) = if (x == active) then false else true 

--This is the new output layer: 
--BIAS IS NOT ABSOLUTE VALUE, BIAS IS LITERAL VALUE 
bias_order = <2, 5, 4, 3, 1>

--Function: 
--Weight IS ABSOLUTE VALUE. 
weight_order(1) = <4, 3, 5, 2, 1>
weight_order(2) = <1, 2, 3, 4, 5>
weight_order(3) = <1, 3, 2, 5, 4>
weight_order(4) = <4, 2, 3, 1, 5>
weight_order(5) = <1, 2, 4, 3, 5>
weight_order(_) = <1,2,4,3,5>

--Function, 
--If yes, COULD be max> 
--Only for, 
--if any is max, 
isMax(n, s) = 
	if (head(s) == n) 
		then 
			True 
		else 
			False
			
couldNodeMax(n, results) = 
	if (not (member(True, { isMax(n, weight_order(i)) | i <- {1..layerSize(layerNo)}, extract_sequence(i, results) == active}))  and 
		isMax(n, bias_order) == False) 
		then 
			False
		else 
			True 
	

--All we need to do, is add this to the guard. 

OutputLayer = let	
	C(0, network_results, empty) = 
		((empty) & context_output!{} -> SKIP )
		[]
		((not empty) & 
			context_output!{ context_translation(i) | i <- {1..#network_results}, couldNodeMax(i, network_results) == True} -> SKIP )
	
	C(index, network_results, empty) = HiddenNodePhase.index?output -> 
										C((index-1), <output>^network_results, emptylogic(empty, output))
										
	within 
		C(layerSize(layerNo), <>, true)

Test = (InputLayer [| {| InputLayerPhase |} |] HiddenLayers) 
--Better if the output interpreter inside the main function, needs to be because of the recursion.
ANN = (( ( (InputLayer [| {| InputLayerPhase |} |] HiddenLayers)  
		[| {| HiddenNodePhase |} |] 
	   OutputLayer) ) ) 
	 

assert ANN :[deadlock-free]
assert Test :[deadlock-free]

extract_sequence(1, sequence) = head(sequence)
extract_sequence(index, sequence) = extract_sequence((index-1), tail(sequence))

layerSize(0) = insize
layerSize(layer) = extract_sequence(layer, layerstructure)

extract_weights(layer, node, index) = extract_sequence(index, 
					(extract_sequence(node, 
						(extract_sequence(layer, weights)))))
--Extract weights of node
extract_biases(layer, node) = (extract_sequence(node, 
								(extract_sequence(layer, biases))))
						
