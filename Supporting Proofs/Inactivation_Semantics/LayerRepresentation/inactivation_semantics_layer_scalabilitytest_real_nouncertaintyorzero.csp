--Inactivation semantics, where each layer is captured instead of each node. 
--We represent the edges using functions, instead of processes. 

--SEMANTIC CONSTANTS--
insize = 5
outsize = 5
layerstructure = <5, 5>
layerNo = #layerstructure 

--maxSize is now the MAXIMUM layerPhase CHANNEL SIZE. 
maxSize = 15


--CHANNELS AND DATA TYPES: 

--Context channel: 

core_real = { -1..1}

--Decisions: 

datatype decisions = coc | wl | wr | sl | sr 


channel context_input:{1..insize}.core_real

channel context_output:Set({coc, wl, wr, sl, sr})

--Adding more to this is terrible for scalability.
datatype Phases = active | inactive

active_val(size) = {(n,x) | n <- {1..size}, x <- {active}}
inactive_val(size) = {(n,x) | n <- {1..size}, x <- {inactive}}

--This is actually what we need, see how long it is scalable for. 
--Extract from the four sets of pairs. 
--Parameter of how long. 
pair_extract(set_indexes, size) = union(
						{(n,x) | (n,x) <- active_val(size), member(n, set_indexes)},
						{(n,x) | (n,x) <- inactive_val(size), member(n, diff({1..size}, set_indexes))})

	
--We need to do this, for sets of length 15, and 5. 
--This is SCALABLE, for 15 nodes, this is the approach we will take. 
--Layer approach, as well, we will still take, I think, although, 
--Why can't we evaluate this? Even for 5 nodes? We can, 
all_pairs = Union({
		{pair_extract(s, 5) | s <- Set({1..5})},
		{{(1,active)}}
		})
	    
			 

--The actual one, we need is: 


channel LayerPhase:{0..layerNo}.{1..4}.all_pairs
							
--These are the internal communications now. 
channel NodePhase:{0..layerNo}.{1..maxSize}.Phases

channel end 

weights = 
{
	( (1,1,1), active),
	( (1,1,2), active),
	( (2,1,1), active)
}
	
biases = 
{
	( (1,1), active), 
	( (2,1), active)
}

InputNode(n) = (NodePhase.0.n.active -> SKIP) 

--Channel need to have, ceiling(maxSize / layerSize) number of sub channels. 
--We have the full, real, set. 
--We need to split this, return a sequence, so we can just use head(s)
--then head(tail(s) then head(tail(tail(s)), lazy but it works. 
--ALways needs to be a sequence of 3 sets, the empty set is fine. 
--When we recieve, need to just recieve, then take union of all, in each node. 
--we can know the size of the layer, with layerSize()
--need to know how many elements we have. 
--Split into sections of 15, do it recursively, maximum
--Splits, until every one gets to a set that it can handle. 
--
--we don't know the indicies, take last? 
--Make it into a sequence, take first 15. 
--We don't know the index, that it starts with. 
--all have some number though. make a sequence, take first, subsequence, 
--head x times, 
--




--Hard coded for 5 inputs,
InputNodeCollator(node) = let
	C(0, NodeResults) = 
		LayerPhase.0.1.NodeResults -> LayerPhase.0.2.{(1,active)} -> LayerPhase.0.3.{(1,active)} -> LayerPhase.0.4.{(1,active)} ->  SKIP
		
	C(node, NodeResults) = NodePhase.0.node?node_phase -> C((node-1), union({(node, node_phase)}, NodeResults))
	within 
		C(node, {})


InputLayer = 
	(||| i : {1..insize} @ InputNode(i)) 
	[| {| NodePhase.0 |} |] 
	InputNodeCollator(insize)
	
	
EdgeLogic(input_phase, weight, first) = 
	if(first == true) then 
		if(input_phase == inactive)
			then 
				if(weight == inactive)
					then 
						active
					else
						inactive
			else
				if(weight == inactive)
					then
						inactive
					else
						active
	else 
		if(input_phase == inactive)
			then 
				inactive
			else if (input_phase == active)
				then 
				(if(weight == inactive)
					then
						inactive
					else
						active)
			else
				(if(weight == inactive)
					then
						inactive
					else
						active)

--Needed to extract a value from singleton set. 
--If its empty, return? Should never be empty, make sure by construction 
--it thinks that the result could be > 1, but it isn't. We need a base case for layer extraction. 
--When creating the channels, FDR thinks that it could be wrong, but it never is, add this pattern to prevent this.
--we use pick for weights, biases, and activations, inactive, is the base case, this should never happen though.
pick({}) = active
--pick if there is multiple, only possible in theory: 
pick({x}) = x
pick(x) = active

--This should always return a singleton set, because every index should be unique.
--Weights is a function, not a relation. 
--Make sure this is never out of range, otherwise will error.
--WeightExtraction(layer, node, index) = 
	--pick({weight | (weight_index, weight) <- weights, weight_index == (layer,node,index)})

WeightExtraction(layer, node, index) = active 
BiasExtraction(layer, node) = active 

--BiasExtraction(layer, node) = 
--pick({bias | (bias_index, bias) <- biases, bias_index == (layer,node)})
	
--Applies a weight to a input, this replaces the edge process. 
--If we are on the first layer, we need to extract the weights considering the output of the input nodes could be negative. 
--Every other node, use ReLU law, cannot be negative. 
WeightApplicationSingle((prev_node,result), layer, node) = 
	if(layer == 1)
		then 
			( (prev_node), 
				EdgeLogic(result, WeightExtraction(layer, node, prev_node), true)
			)
		else 
			( (prev_node), 
				EdgeLogic(result, WeightExtraction(layer, node, prev_node), false)
			)

--Need to do this for an entire set of 
--Set comprehension, because this should return the modified set. 
--Set comprehension, we want a modified set, which is weightapplicationsingle. 
--How do we get layer and node? 

WeightApplicationFunction(layer_input, layer, node) = 
	{ WeightApplicationSingle((prev_node,result), layer, node) | 
		(prev_node, result) <- layer_input
	}


--Extracts the node indexed by node, the first argument, from the set of tuples weightedinputs.
--Assumes that weightedinputs is a function, will fail otherwise. 
--If we GET THE EMPTY SET, WE NEED A BASE CASE: 
--This should never happen in reality, when we are running the node, but because 
--we use a parameteric type, the type will allow for different sizes. 
--we will know, if it tries to evaluate node which is greater than weighted inputs. 
--Assumed that the pairs are constructed correctly.

ExtractActivation(node, weightedinputs) = 
	if(node>card(weightedinputs)) 
		then
			active 
		else 
			pick({activation | (node_index, activation) <- weightedinputs, node_index == node})
	
--Have it the same for now, benefits, check really easily if any are, activation is when, bias is negative, if it 
--can't be activated, inactive. If no weighted nodes are active, 
--Check if is the empty set. for the entire set, 
--If any AREN'T active, uncertain? if any are uncertain, then we might activate, 
--Uncertainty ALWAYS REMOVED BY THE WEIGHTING, CAN ONLY BE ZERO, ACTIVE, OR INACTIVE HERE. Take worst case for uncertainty in weight logic. 
ActivationLogic(weightedinputs) = 
	if (card({ (node_index, activation) | (node_index, activation) <- weightedinputs, activation == active}) > 0)
		then 
			true
		else
			false

InActivationLogic(weightedinputs) = 
	if (card({ (node_index, activation) | (node_index, activation) <- weightedinputs, activation == inactive}) > 0)
		then 
			true
		else
			false

--First layer nodes need to be different, 
Node(l, n) = LayerPhase.(l-1).1?layer_input_1 -> LayerPhase.(l-1).2?layer_input_2 -> LayerPhase.(l-1).3?layer_input_3 -> LayerPhase.(l-1).4?layer_input_4 -> (
				( BiasExtraction(l, n) == inactive & ( 
						( ActivationLogic(WeightApplicationFunction(Union({layer_input_1, layer_input_2, layer_input_3, layer_input_4}), l, n)) == false & 
							NodePhase.l.n!inactive -> SKIP)
						[]
						( ActivationLogic(WeightApplicationFunction(Union({layer_input_1, layer_input_2, layer_input_3, layer_input_4}), l, n)) == true & 
							NodePhase.l.n!active -> SKIP
							|~|
							NodePhase.l.n!inactive -> SKIP
							)
							) )
				[]
				( BiasExtraction(l,n) == active & (
					( InActivationLogic(WeightApplicationFunction(Union({layer_input_1, layer_input_2, layer_input_3, layer_input_4}), l, n)) == false & 
						NodePhase.l.n!active -> SKIP)
					[]
					( InActivationLogic(WeightApplicationFunction(Union({layer_input_1, layer_input_2, layer_input_3, layer_input_4}), l, n)) == true & 
						NodePhase.l.n!active -> SKIP
						|~|
						NodePhase.l.n!inactive -> SKIP )
					) )
				)

--We just need NodeCollator, that is the layer, then to compose the input layers together, then rename them to the context.
--Then done. 

split_set_50(s) = 
	let 
		f = set(take_n(15, seq(s)))
		se = set(take_n(15, seq(diff(s, f))))
		t = set(take_n(15, seq(diff(s, Union({f,se})))))
		fourth = set(take_n(5, seq(diff(s, Union({f,se,t})))))
	within
	<f, se, t, fourth>

--

NodeCollator(l) = let
	C(l,0,NodeResults) = 
		((card(NodeResults) == 5) & LayerPhase.l.1!NodeResults -> LayerPhase.l.2!{(1,active)} -> LayerPhase.l.3!{(1,active)} -> LayerPhase.l.4!{(1,active)} -> SKIP)
		[]
		((card(NodeResults) == 50) & LayerPhase.l.1!extract_sequence(1,split_set_50(NodeResults))
						-> LayerPhase.l.2!extract_sequence(2,split_set_50(NodeResults)) 
							-> LayerPhase.l.3!extract_sequence(3,split_set_50(NodeResults))
								-> LayerPhase.l.4!extract_sequence(4,split_set_50(NodeResults))
									-> SKIP)
		
	C(l,n,NodeResults) = 
		NodePhase.l.n?node_phase -> C(l, (n-1), union({(n, node_phase)}, NodeResults))
		
	within 
		C(l, layerSize(l), {})


--They all need to synchronise, on the layeroutput from previous layer, 

Layer(l) = 
	(([| {| LayerPhase.(l-1) |} |]  i : {1..layerSize(l)} @ Node(l, i) )
	[| {| NodePhase.l |} |] 
	NodeCollator(l))

HiddenLayers = 
	|| i : {1..(layerNo-1)} @
		[ {| LayerPhase.(i-1), LayerPhase.i, NodePhase.i |} ] 
		Layer(i)
		

OutputLayer = Layer(layerNo)

ANN_Visible = ( (InputLayer [| {| LayerPhase.0 |} |] HiddenLayers) [| {| LayerPhase.(layerNo-1) |} |] 
	   OutputLayer) ; ANN_Visible

assert InputLayer :[deadlock-free[FD]]

assert ANN_Visible :[deadlock-free[FD]]
assert ANN_Visible :[divergence-free]
assert ANN_Visible :[deterministic]

--No hiding for now. 

layerSize(0) = insize
layerSize(layer) = extract_sequence(layer, layerstructure)

extract_sequence(1, sequence) = head(sequence)
extract_sequence(index, sequence) = extract_sequence((index-1), tail(sequence))

--Take first n elements of sequence: 
take_n(0, seq) = <>
take_n(n, seq) = <head(seq)> ^ take_n((n-1), tail(seq))



	
