--Inactivation semantics, where each layer is captured instead of each node. 
--We represent the edges using functions, instead of processes. 

--SEMANTIC CONSTANTS--
insize = 2
outsize = 1
layerstructure = <1, 1>
layerNo = #layerstructure 
maxSize = 2


--CHANNELS AND DATA TYPES: 

--Context channel: 

core_real = { -1..1}

--Decisions: 

datatype decisions = coc | wl | wr | sl | sr 
--We want product type 
--For every pair, we need n-ary pairs, don't we? 

--this helps, this is all combinations, need for all x and ys, to run this: 
--For all combinations, FOR EVERYTHING
--Need n-ary version of this, or, for every combination, 
--this is what we need, 
--

channel context_input:{1..insize}.core_real

channel context_output:Set({coc, wl, wr, sl, sr})


datatype Phases = active | inactive | zero | uncertain
--This only works for ALL NODES ACTIVE, or inactive, or uncertain, NOT A COMBINATION OF THEM.
--{ { (n, p) | n <- {1..l} } | l <- {1, 2}, p <- Phases} 

--if there is two xs that are the same, check a set, 
--recursive, choose any value, 
--STARTS AS FALSE, TURNS TRUE if we find one that is the same? 
--for every element, 

--For a set, 

--make a set of each number, if any number, card greater than 1. 
--For 
distinct(i, set_pairs) = 
	if card( { x | (x,y) <- set_pairs, x == i}) > 1 
		then 
			false 
		else 
			true 

--IF ANY IS FALSE, ENTIRE THING IS FALSE. 
distinct_set(set_pairs) = 
	if member(false, { distinct(i, set_pairs) | i <- {1..card(set_pairs)}})
		then 
			false 
		else 
			true 

channel LayerPhase:{0..layerNo}.{ x | x <- Set({(n,p) | n <- {1..maxSize}, p <- Phases}), 
							card(x) == 1 or card(x) == 2 and 
							distinct_set(x)
							}

--These are the internal communications now. 
channel NodePhase:{0..layerNo}.{1..maxSize}.Phases

channel end 

weights = 
{
	( (1,1,1), active),
	( (1,1,2), active),
	( (2,1,1), active)
}
	
biases = 
{
	( (1,1), active), 
	( (2,1), active)
}

InputNode(n) = (NodePhase.0.n.active -> SKIP) [] (NodePhase.0.n.inactive -> SKIP)

InputNodeCollator(node) = let
	C(0, NodeResults) = 
		LayerPhase.0.NodeResults -> SKIP
		
	C(node, NodeResults) = NodePhase.0.node?node_phase -> 
										C((node-1), union({(node, node_phase)}, NodeResults))
	within 
		C(node, {})


InputLayer = 
	(||| i : {1..insize} @ InputNode(i)) 
	[| {| NodePhase.0 |} |] 
	InputNodeCollator(insize)
	
	
EdgeLogic(input_phase, weight, first) = 
	if(first == true) then 
		if(input_phase == inactive)
			then 
				if(weight == inactive)
					then 
						active
					else
						inactive
			else
				if(weight == inactive)
					then
						inactive
					else
						active
	else 
		if(input_phase == inactive)
			then 
				zero
			else if (input_phase == active)
				then 
				(if(weight == inactive)
					then
						inactive
					else
						active)
			else
				(if(weight == inactive)
					then
						inactive
					else
						active)

--Needed to extract a value from singleton set. 
--If its empty, return? Should never be empty, make sure by construction 
--it thinks that the result could be > 1, but it isn't. We need a base case for layer extraction. 
--When creating the channels, FDR thinks that it could be wrong, but it never is, add this pattern to prevent this.
--we use pick for weights, biases, and activations, inactive, is the base case, this should never happen though.
pick({}) = inactive
--pick if there is multiple, only possible in theory: 
pick({x}) = x
pick(x) = inactive

--This should always return a singleton set, because every index should be unique.
--Weights is a function, not a relation. 
--Make sure this is never out of range, otherwise will error.
WeightExtraction(layer, node, index) = 
	pick({weight | (weight_index, weight) <- weights, weight_index == (layer,node,index)})
	
BiasExtraction(layer, node) = 
	pick({bias | (bias_index, bias) <- biases, bias_index == (layer,node)})
	
--Applies a weight to a input, this replaces the edge process. 
--If we are on the first layer, we need to extract the weights considering the output of the input nodes could be negative. 
--Every other node, use ReLU law, cannot be negative. 
WeightApplicationSingle((prev_node,result), layer, node) = 
	if(layer == 1)
		then 
			( (prev_node), 
				EdgeLogic(result, WeightExtraction(layer, node, prev_node), true)
			)
		else 
			( (prev_node), 
				EdgeLogic(result, WeightExtraction(layer, node, prev_node), false)
			)

--Need to do this for an entire set of 
--Set comprehension, because this should return the modified set. 
--Set comprehension, we want a modified set, which is weightapplicationsingle. 
--How do we get layer and node? 

WeightApplicationFunction(layer_input, layer, node) = 
	{ WeightApplicationSingle((prev_node,result), layer, node) | 
		(prev_node, result) <- layer_input
	}


--Extracts the node indexed by node, the first argument, from the set of tuples weightedinputs.
--Assumes that weightedinputs is a function, will fail otherwise. 
--If we GET THE EMPTY SET, WE NEED A BASE CASE: 
--This should never happen in reality, when we are running the node, but because 
--we use a parameteric type, the type will allow for different sizes. 
--we will know, if it tries to evaluate node which is greater than weighted inputs. 
--Assumed that the pairs are constructed correctly.

ExtractActivation(node, weightedinputs) = 
	if(node>card(weightedinputs)) 
		then
			inactive 
		else 
			pick({activation | (node_index, activation) <- weightedinputs, node_index == node})
	
--Have it the same for now, benefits, check really easily if any are, activation is when, bias is negative, if it 
--can't be activated, inactive. If no weighted nodes are active, 
--Check if is the empty set. for the entire set, 
--If any AREN'T active, uncertain? if any are uncertain, then we might activate, 
--Uncertainty ALWAYS REMOVED BY THE WEIGHTING, CAN ONLY BE ZERO, ACTIVE, OR INACTIVE HERE. Take worst case for uncertainty in weight logic. 
ActivationLogic(weightedinputs) = 
	if (card({ (node_index, activation) | (node_index, activation) <- weightedinputs, activation == active}) > 0)
		then 
			true
		else
			false

InActivationLogic(weightedinputs) = 
	if (card({ (node_index, activation) | (node_index, activation) <- weightedinputs, activation == inactive}) > 0)
		then 
			true
		else
			false

--First layer nodes need to be different, 
Node(l, n) = LayerPhase.(l-1)?layer_input -> (
				( BiasExtraction(l, n) == inactive & ( 
						( ActivationLogic(WeightApplicationFunction(layer_input, l, n)) == false & 
							NodePhase.l.n!inactive -> SKIP)
						[]
						( ActivationLogic(WeightApplicationFunction(layer_input, l, n)) == true & 
							NodePhase.l.n!uncertain -> SKIP )
							) )
				[]
				( BiasExtraction(l,n) == active & (
					( InActivationLogic(WeightApplicationFunction(layer_input, l, n)) == false & 
						NodePhase.l.n!active -> SKIP)
					[]
					( InActivationLogic(WeightApplicationFunction(layer_input, l, n)) == true & 
						NodePhase.l.n!uncertain -> SKIP )
					) )
				)

--We just need NodeCollator, that is the layer, then to compose the input layers together, then rename them to the context.
--Then done. 


NodeCollator(l) = let
	C(l,0,NodeResults) = 
		LayerPhase.l!NodeResults -> SKIP
		
	C(l,n,NodeResults) = 
		NodePhase.l.n?node_phase -> C(l, (n-1), union({(n, node_phase)}, NodeResults))
		
	within 
		C(l, layerSize(l), {})


--They all need to synchronise, on the layeroutput from previous layer, 

Layer(l) = 
	(([| {| LayerPhase.(l-1) |} |]  i : {1..layerSize(l)} @ Node(l, i) )
	[| {| NodePhase.l |} |] 
	NodeCollator(l))

HiddenLayers = 
	|| i : {1..(layerNo-1)} @
		[ {| LayerPhase.(i-1), LayerPhase.i, NodePhase.i |} ] 
		Layer(i)
		

OutputLayer = Layer(layerNo)


ANN_Visible = ( (InputLayer [| {| LayerPhase.0 |} |] HiddenLayers) [| {| LayerPhase.(layerNo-1) |} |] 
	   OutputLayer) ; ANN_Visible

assert ANN_Visible :[deadlock-free[FD]]
assert ANN_Visible :[divergence-free]
assert ANN_Visible :[deterministic]

--No hiding for now. 

layerSize(0) = insize
layerSize(layer) = extract_sequence(layer, layerstructure)

extract_sequence(1, sequence) = head(sequence)
extract_sequence(index, sequence) = extract_sequence((index-1), tail(sequence))



	
